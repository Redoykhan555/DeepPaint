{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from PIL import Image\n",
    "from typing import List\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab2rgb_transpose(img_l, img_ab):\n",
    "    ''' INPUTS\n",
    "            img_l     1xXxX     [0,100]\n",
    "            img_ab     2xXxX     [-100,100]\n",
    "        OUTPUTS\n",
    "            returned value is XxXx3 '''\n",
    "    print(\"labtoRGB:\",img_l.max(),img_l.min(),img_ab.max(),img_ab.min())\n",
    "    pred_lab = np.concatenate((img_l, img_ab), axis=0).transpose((1, 2, 0))\n",
    "    pred_rgb = (np.clip(color.lab2rgb(pred_lab), 0, 1) * 255).astype('uint8')\n",
    "    return pred_rgb\n",
    "\n",
    "\n",
    "def rgb2lab_transpose(img_rgb):\n",
    "    ''' INPUTS\n",
    "            img_rgb XxXx3\n",
    "        OUTPUTS\n",
    "            returned value is 3xXxX '''\n",
    "    return color.rgb2lab(img_rgb).transpose((2, 0, 1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SIGGRAPHGenerator(nn.Module):\n",
    "    def __init__(self, dist=False):\n",
    "        super(SIGGRAPHGenerator, self).__init__()\n",
    "        self.dist = dist\n",
    "        use_bias = True\n",
    "        norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        # Conv1\n",
    "        model1 = [nn.Conv2d(4, 64, kernel_size=3, stride=1, padding=1, bias=use_bias), ]\n",
    "        model1 += [nn.ReLU(True), ]\n",
    "        model1 += [nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=use_bias), ]\n",
    "        model1 += [nn.ReLU(True), ]\n",
    "        model1 += [norm_layer(64), ]\n",
    "        # add a subsampling operation\n",
    "\n",
    "        # Conv2\n",
    "        model2 = [nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=use_bias), ]\n",
    "        model2 += [nn.ReLU(True), ]\n",
    "        model2 += [nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=use_bias), ]\n",
    "        model2 += [nn.ReLU(True), ]\n",
    "        model2 += [norm_layer(128), ]\n",
    "        # add a subsampling layer operation\n",
    "\n",
    "        # Conv3\n",
    "        model3 = [nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=use_bias), ]\n",
    "        model3 += [nn.ReLU(True), ]\n",
    "        model3 += [nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=use_bias), ]\n",
    "        model3 += [nn.ReLU(True), ]\n",
    "        model3 += [nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=use_bias), ]\n",
    "        model3 += [nn.ReLU(True), ]\n",
    "        model3 += [norm_layer(256), ]\n",
    "        # add a subsampling layer operation\n",
    "\n",
    "        # Conv4\n",
    "        model4 = [nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1, bias=use_bias), ]\n",
    "        model4 += [nn.ReLU(True), ]\n",
    "        model4 += [nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=use_bias), ]\n",
    "        model4 += [nn.ReLU(True), ]\n",
    "        model4 += [nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=use_bias), ]\n",
    "        model4 += [nn.ReLU(True), ]\n",
    "        model4 += [norm_layer(512), ]\n",
    "\n",
    "        # Conv5\n",
    "        model5 = [nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias), ]\n",
    "        model5 += [nn.ReLU(True), ]\n",
    "        model5 += [nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias), ]\n",
    "        model5 += [nn.ReLU(True), ]\n",
    "        model5 += [nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias), ]\n",
    "        model5 += [nn.ReLU(True), ]\n",
    "        model5 += [norm_layer(512), ]\n",
    "\n",
    "        # Conv6\n",
    "        model6 = [nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias), ]\n",
    "        model6 += [nn.ReLU(True), ]\n",
    "        model6 += [nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias), ]\n",
    "        model6 += [nn.ReLU(True), ]\n",
    "        model6 += [nn.Conv2d(512, 512, kernel_size=3, dilation=2, stride=1, padding=2, bias=use_bias), ]\n",
    "        model6 += [nn.ReLU(True), ]\n",
    "        model6 += [norm_layer(512), ]\n",
    "\n",
    "        # Conv7\n",
    "        model7 = [nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=use_bias), ]\n",
    "        model7 += [nn.ReLU(True), ]\n",
    "        model7 += [nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=use_bias), ]\n",
    "        model7 += [nn.ReLU(True), ]\n",
    "        model7 += [nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=use_bias), ]\n",
    "        model7 += [nn.ReLU(True), ]\n",
    "        model7 += [norm_layer(512), ]\n",
    "\n",
    "        # Conv7\n",
    "        model8up = [nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=use_bias)]\n",
    "        model3short8 = [nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=use_bias), ]\n",
    "\n",
    "        model8 = [nn.ReLU(True), ]\n",
    "        model8 += [nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=use_bias), ]\n",
    "        model8 += [nn.ReLU(True), ]\n",
    "        model8 += [nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=use_bias), ]\n",
    "        model8 += [nn.ReLU(True), ]\n",
    "        model8 += [norm_layer(256), ]\n",
    "\n",
    "        # Conv9\n",
    "        model9up = [nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=use_bias), ]\n",
    "        model2short9 = [nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=use_bias), ]\n",
    "        # add the two feature maps above\n",
    "\n",
    "        model9 = [nn.ReLU(True), ]\n",
    "        model9 += [nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=use_bias), ]\n",
    "        model9 += [nn.ReLU(True), ]\n",
    "        model9 += [norm_layer(128), ]\n",
    "\n",
    "        # Conv10\n",
    "        model10up = [nn.ConvTranspose2d(128, 128, kernel_size=4, stride=2, padding=1, bias=use_bias), ]\n",
    "        model1short10 = [nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=use_bias), ]\n",
    "        # add the two feature maps above\n",
    "\n",
    "        model10 = [nn.ReLU(True), ]\n",
    "        model10 += [nn.Conv2d(128, 128, kernel_size=3, dilation=1, stride=1, padding=1, bias=use_bias), ]\n",
    "        model10 += [nn.LeakyReLU(negative_slope=.2), ]\n",
    "\n",
    "        # classification output\n",
    "        model_class = [nn.Conv2d(256, 529, kernel_size=1, padding=0, dilation=1, stride=1, bias=use_bias), ]\n",
    "\n",
    "        # regression output\n",
    "        model_out = [nn.Conv2d(128, 2, kernel_size=1, padding=0, dilation=1, stride=1, bias=use_bias), ]\n",
    "        model_out += [nn.Tanh()]\n",
    "\n",
    "        self.model1 = nn.Sequential(*model1)\n",
    "        self.model2 = nn.Sequential(*model2)\n",
    "        self.model3 = nn.Sequential(*model3)\n",
    "        self.model4 = nn.Sequential(*model4)\n",
    "        self.model5 = nn.Sequential(*model5)\n",
    "        self.model6 = nn.Sequential(*model6)\n",
    "        self.model7 = nn.Sequential(*model7)\n",
    "        self.model8up = nn.Sequential(*model8up)\n",
    "        self.model8 = nn.Sequential(*model8)\n",
    "        self.model9up = nn.Sequential(*model9up)\n",
    "        self.model9 = nn.Sequential(*model9)\n",
    "        self.model10up = nn.Sequential(*model10up)\n",
    "        self.model10 = nn.Sequential(*model10)\n",
    "        self.model3short8 = nn.Sequential(*model3short8)\n",
    "        self.model2short9 = nn.Sequential(*model2short9)\n",
    "        self.model1short10 = nn.Sequential(*model1short10)\n",
    "\n",
    "        self.model_class = nn.Sequential(*model_class)\n",
    "        self.model_out = nn.Sequential(*model_out)\n",
    "\n",
    "        self.upsample4 = nn.Sequential(*[nn.Upsample(scale_factor=4, mode='nearest'), ])\n",
    "        self.softmax = nn.Sequential(*[nn.Softmax(dim=1), ])\n",
    "\n",
    "    def forward(self, input_A, input_B, mask_B):\n",
    "        # input_A \\in [-50,+50]\n",
    "        # input_B \\in [-110, +110]\n",
    "        # mask_B \\in [0, +0.5]\n",
    "\n",
    "        input_A = torch.Tensor(input_A).cuda()[None, :, :, :]\n",
    "        input_B = torch.Tensor(input_B).cuda()[None, :, :, :]\n",
    "        mask_B = torch.Tensor(mask_B).cuda()[None, :, :, :]\n",
    "\n",
    "        conv1_2 = self.model1(torch.cat((input_A / 100., input_B / 110., mask_B - .5), dim=1))\n",
    "        conv2_2 = self.model2(conv1_2[:, :, ::2, ::2])\n",
    "        conv3_3 = self.model3(conv2_2[:, :, ::2, ::2])\n",
    "        conv4_3 = self.model4(conv3_3[:, :, ::2, ::2])\n",
    "        conv5_3 = self.model5(conv4_3)\n",
    "        conv6_3 = self.model6(conv5_3)\n",
    "        conv7_3 = self.model7(conv6_3)\n",
    "\n",
    "        conv8_up = self.model8up(conv7_3) + self.model3short8(conv3_3)\n",
    "        conv8_3 = self.model8(conv8_up)\n",
    "\n",
    "        if(self.dist):\n",
    "            out_cl = self.upsample4(self.softmax(self.model_class(conv8_3) * .2))\n",
    "\n",
    "            conv9_up = self.model9up(conv8_3) + self.model2short9(conv2_2)\n",
    "            conv9_3 = self.model9(conv9_up)\n",
    "            conv10_up = self.model10up(conv9_3) + self.model1short10(conv1_2)\n",
    "            conv10_2 = self.model10(conv10_up)\n",
    "            out_reg = self.model_out(conv10_2) * 110\n",
    "\n",
    "            return (out_reg * 110, out_cl)\n",
    "        else:\n",
    "            conv9_up = self.model9up(conv8_3) + self.model2short9(conv2_2)\n",
    "            conv9_3 = self.model9(conv9_up)\n",
    "            conv10_up = self.model10up(conv9_3) + self.model1short10(conv1_2)\n",
    "            conv10_2 = self.model10(conv10_up)\n",
    "            out_reg = self.model_out(conv10_2)\n",
    "            return out_reg * 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(img_rgb,inp_ab,inp_mask):\n",
    "    lab_image = color.rgb2lab(img_rgb).transpose((2, 0, 1))\n",
    "    img_l = lab_image[[0],...]\n",
    "    img_ab = lab_image[1:,...]\n",
    "    img_l -= 50.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out_ab = model(img_l,inp_ab,inp_mask)\n",
    "    img = lab2rgb_transpose(img_l+50.0,out_ab.detach().cpu().numpy()[0])\n",
    "    arr = np.array(img)\n",
    "    ab = np.abs(arr)\n",
    "    print(\"Out:\",arr.mean(), arr.min(), arr.max(), ab.mean(), ab.min(), ab.max())\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "def put_point(input_ab,mask,loc,p,val):\n",
    "    print(\"Put points:\",val.shape)\n",
    "    val = val[:,np.newaxis,np.newaxis]\n",
    "    input_ab[:,loc[0]-p:loc[0]+p+1,loc[1]-p:loc[1]+p+1] = val\n",
    "    mask[:,loc[0]-p:loc[0]+p+1,loc[1]-p:loc[1]+p+1] = 1\n",
    "    return (input_ab,mask)\n",
    "\n",
    "def convRGB(rgb):\n",
    "    im = [[rgb]]\n",
    "    im = np.array(im)/255\n",
    "    return color.rgb2lab(im)[0][0]\n",
    "\n",
    "def colorize(img:Image.Image,points:List):\n",
    "    arr = np.array(img)\n",
    "    ab = np.abs(arr)\n",
    "    print(\"In:\",arr.mean(),arr.min(),arr.max(),ab.mean(),ab.min(),ab.max())\n",
    "    size = img.size\n",
    "    inp_ab = np.zeros((2,)+size)\n",
    "    inp_mask = np.zeros((1,)+size)\n",
    "    for pos,col,r in points:\n",
    "        print(pos,r)\n",
    "        col = convRGB(col)\n",
    "        put_point(inp_ab,inp_mask,pos,r,col[1:])\n",
    "    print(\"*\"*16)\n",
    "    return run(img,inp_ab,inp_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SIGGRAPHGenerator().cuda().eval()\n",
    "state_dic = torch.load(\"d:/DeepPaint/weights/colorizer.pth\")\n",
    "model.load_state_dict(state_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model1.0.bias',\n",
       " 'model1.0.weight',\n",
       " 'model1.2.bias',\n",
       " 'model1.2.weight',\n",
       " 'model1.4.bias',\n",
       " 'model1.4.weight',\n",
       " 'model10.1.bias',\n",
       " 'model10.1.weight',\n",
       " 'model10up.0.bias',\n",
       " 'model10up.0.weight',\n",
       " 'model1short10.0.bias',\n",
       " 'model1short10.0.weight',\n",
       " 'model2.0.bias',\n",
       " 'model2.0.weight',\n",
       " 'model2.2.bias',\n",
       " 'model2.2.weight',\n",
       " 'model2.4.bias',\n",
       " 'model2.4.weight',\n",
       " 'model2short9.0.bias',\n",
       " 'model2short9.0.weight',\n",
       " 'model3.0.bias',\n",
       " 'model3.0.weight',\n",
       " 'model3.2.bias',\n",
       " 'model3.2.weight',\n",
       " 'model3.4.bias',\n",
       " 'model3.4.weight',\n",
       " 'model3.6.bias',\n",
       " 'model3.6.weight',\n",
       " 'model3short8.0.bias',\n",
       " 'model3short8.0.weight',\n",
       " 'model4.0.bias',\n",
       " 'model4.0.weight',\n",
       " 'model4.2.bias',\n",
       " 'model4.2.weight',\n",
       " 'model4.4.bias',\n",
       " 'model4.4.weight',\n",
       " 'model4.6.bias',\n",
       " 'model4.6.weight',\n",
       " 'model5.0.bias',\n",
       " 'model5.0.weight',\n",
       " 'model5.2.bias',\n",
       " 'model5.2.weight',\n",
       " 'model5.4.bias',\n",
       " 'model5.4.weight',\n",
       " 'model5.6.bias',\n",
       " 'model5.6.weight',\n",
       " 'model6.0.bias',\n",
       " 'model6.0.weight',\n",
       " 'model6.2.bias',\n",
       " 'model6.2.weight',\n",
       " 'model6.4.bias',\n",
       " 'model6.4.weight',\n",
       " 'model6.6.bias',\n",
       " 'model6.6.weight',\n",
       " 'model7.0.bias',\n",
       " 'model7.0.weight',\n",
       " 'model7.2.bias',\n",
       " 'model7.2.weight',\n",
       " 'model7.4.bias',\n",
       " 'model7.4.weight',\n",
       " 'model7.6.bias',\n",
       " 'model7.6.weight',\n",
       " 'model8.1.bias',\n",
       " 'model8.1.weight',\n",
       " 'model8.3.bias',\n",
       " 'model8.3.weight',\n",
       " 'model8.5.bias',\n",
       " 'model8.5.weight',\n",
       " 'model8up.0.bias',\n",
       " 'model8up.0.weight',\n",
       " 'model9.1.bias',\n",
       " 'model9.1.weight',\n",
       " 'model9.3.bias',\n",
       " 'model9.3.weight',\n",
       " 'model9up.0.bias',\n",
       " 'model9up.0.weight',\n",
       " 'model_class.0.bias',\n",
       " 'model_class.0.weight',\n",
       " 'model_out.0.bias',\n",
       " 'model_out.0.weight'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks = set(state_dic.keys())\n",
    "ps = set([n for n,v in model.named_parameters()])\n",
    "ks.intersection(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dic._metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod in model.modules():\n",
    "    print(mod.__class__.__name__)#,[n for n,v in mod.named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
