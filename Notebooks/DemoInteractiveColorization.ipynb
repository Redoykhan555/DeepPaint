{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Demo of Interactive Deep Colorization\n",
    "\n",
    "This iPython Notebook gives a quick demonstration of our system, and requires a working installation of Caffe. For the full demo with our user interface, see the README of this repository (QT installation is required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import colorize_image as CI\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Choose gpu to run the model on\n",
    "gpu_id = 0\n",
    "\n",
    "colorModel = CI.ColorizeImageTorch(Xd=256)\n",
    "colorModel.prep_net(path=\"d:/colorize/models/pytorch/pytorch.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "colorModel.load_image('d:/Images/Bangabandhu.jpeg') # load an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorModel.img_l_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Default prediction\n",
    "\n",
    "First, let's see what the model produces when given no user points. It is performing automatic colorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros((1,256,256)) # giving no user points, so mask is all 0's\n",
    "input_ab = np.zeros((2,256,256)) # ab values of user points, default to 0 for no input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_out = colorModel.net_forward(input_ab,mask) # run model, returns 256x256 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray_fullres = colorModel.get_img_gray_fullres() # get grayscale image at fullresolution\n",
    "img_out_fullres = colorModel.get_img_fullres() # get image at full resolution\n",
    "\n",
    "# show result\n",
    "plt.figure(figsize=(7,3))\n",
    "plt.imshow(np.concatenate((img_gray_fullres,img_out_fullres),axis=1)); plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "im = Image.fromarray(img_out_fullres)\n",
    "im.save(\"your_file.jpeg\")\n",
    "im = Image.fromarray(img_gray_fullres)\n",
    "im.save(\"your_grey.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding user inputs\n",
    "\n",
    "Let's now add the ability to add user inputs. Function ```put_point()```, defined below, will add user input of color ```val``` at location ```loc``` with size ```(2p+1)x(2p+1)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_point(input_ab,mask,loc,p,val):\n",
    "    # input_ab    2x256x256    current user ab input (will be updated)\n",
    "    # mask        1x256x256    binary mask of current user input (will be updated)\n",
    "    # loc         2 tuple      (h,w) of where to put the user input\n",
    "    # p           scalar       half-patch size\n",
    "    # val         2 tuple      (a,b) value of user input\n",
    "    input_ab[:,loc[0]-p:loc[0]+p+1,loc[1]-p:loc[1]+p+1] = np.array(val)[:,np.newaxis,np.newaxis]\n",
    "    mask[:,loc[0]-p:loc[0]+p+1,loc[1]-p:loc[1]+p+1] = 1\n",
    "    return (input_ab,mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will add a single blue point in the middle of the image, and see what the network predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize with no user inputs\n",
    "input_ab = np.zeros((2,256,256))\n",
    "mask = np.zeros((1,256,256))\n",
    "\n",
    "# add a blue point in the middle of the image\n",
    "#(input_ab,mask) = put_point(input_ab,mask,[185,110],3,[80,67])\n",
    "(input_ab,mask) = put_point(input_ab,mask,[185,50],3,[50,-70])\n",
    "#(input_ab,mask) = put_point(input_ab,mask,[50,50],3,[50,-70])\n",
    "#(input_ab,mask) = put_point(input_ab,mask,[50,200],3,[50,-70])\n",
    "(input_ab,mask) = put_point(input_ab,mask,[160,200],3,[50,-70])\n",
    "\n",
    "# call forward\n",
    "img_out = colorModel.net_forward(input_ab,mask)\n",
    "\n",
    "# get mask, input image, and result in full resolution\n",
    "mask_fullres = colorModel.get_img_mask_fullres() # get input mask in full res\n",
    "img_in_fullres = colorModel.get_input_img_fullres() # get input image in full res\n",
    "img_out_fullres = colorModel.get_img_fullres() # get image at full resolution\n",
    "\n",
    "# show user input, along with output\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.imshow(np.concatenate((mask_fullres,img_in_fullres,img_out_fullres),axis=1));\n",
    "plt.title('Mask of user points / Input grayscale with user points / Output olorization')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cup is blue! However, the result above has some leakage into the inside of the cup. Let's clean it up by placing a gray point inside of the cup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a gray point in the inside of the cup\n",
    "(input_ab,mask) = put_point(input_ab,mask,[100,160],3,[0,0])\n",
    "\n",
    "# call forward\n",
    "img_out = colorModel.net_forward(input_ab,mask)\n",
    "\n",
    "# get mask, input image, and result in full resolution\n",
    "mask_fullres = colorModel.get_img_mask_fullres() # get input mask in full res\n",
    "img_in_fullres = colorModel.get_input_img_fullres() # get input image in full res\n",
    "img_out_fullres = colorModel.get_img_fullres() # get image at full resolution\n",
    "\n",
    "# show user input, along with output\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.imshow(np.concatenate((mask_fullres,img_in_fullres,img_out_fullres),axis=1));\n",
    "plt.title('Mask of user points / Input grayscale with user points / Output olorization')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
